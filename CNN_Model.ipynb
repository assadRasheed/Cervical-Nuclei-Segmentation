{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D, Multiply\n",
    "\n",
    "# Define UNet architecture with selective attention mechanism\n",
    "def unet_with_attention(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, UpSampling2D, Multiply\n",
    "\n",
    "# Define UNet architecture with selective attention mechanism\n",
    "def unet_with_attention(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Contracting Path (Encoder)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Add more contracting layers...\n",
    "\n",
    "    # Bottom layer\n",
    "    bn = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pN)\n",
    "    bn = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(bn)\n",
    "\n",
    "    # Selective Attention Mechanism\n",
    "    attention = Multiply()([bn, pN])  # Apply attention to bottom layer features\n",
    "\n",
    "    # Expanding Path (Decoder)\n",
    "    uN = UpSampling2D((2, 2))(attention)\n",
    "    uN = concatenate([uN, cN], axis=-1)\n",
    "    uN = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(uN)\n",
    "    uN = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(uN)\n",
    "\n",
    "    # Add more expanding layers...\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(uN)  # Output segmentation mask\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define Dice loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "    dice_loss = 1 - (numerator + 1) / (denominator + 1)\n",
    "    return dice_loss\n",
    "\n",
    "# Define hybrid loss function combining BCE and Dice loss\n",
    "def hybrid_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    hybrid_loss = bce + dice\n",
    "    return hybrid_loss\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "# Create and compile the model\n",
    "model = unet_with_attention(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss=hybrid_loss, metrics=[dice_loss, 'accuracy'])\n",
    "\n",
    "# Train your model\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # Calculate IoU, DSC, Precision, and Recall\n",
    "    iou = tf.metrics.MeanIoU(num_classes=num_classes)(test_labels, predictions)\n",
    "    dsc = dice_loss(test_labels, predictions)\n",
    "    precision = tf.keras.metrics.Precision()(test_labels, predictions)\n",
    "    recall = tf.keras.metrics.Recall()(test_labels, predictions)\n",
    "    \n",
    "    print(f\"IoU: {iou}, DSC: {dsc}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "# Evaluate the model using test data and labels\n",
    "evaluate_model(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f748e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, concatenate, UpSampling2D, Add, Multiply\n",
    "\n",
    "# Define DeepLab-v3 architecture with selective attention mechanism\n",
    "def deeplab_with_attention(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, concatenate, UpSampling2D, Add, Multiply\n",
    "\n",
    "def _conv2d_bn_relu(input_tensor, filters, kernel_size, padding='same', dilation_rate=1):\n",
    "    x = Conv2D(filters, kernel_size, padding=padding, dilation_rate=dilation_rate)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def _aspp(input_tensor):\n",
    "    d1 = _conv2d_bn_relu(input_tensor, 256, 1)\n",
    "    d6 = _conv2d_bn_relu(input_tensor, 256, 3, dilation_rate=6)\n",
    "    d12 = _conv2d_bn_relu(input_tensor, 256, 3, dilation_rate=12)\n",
    "    d18 = _conv2d_bn_relu(input_tensor, 256, 3, dilation_rate=18)\n",
    "\n",
    "    # Image-level features\n",
    "    image_features = AveragePooling2D(pool_size=(input_tensor.shape[1], input_tensor.shape[2]))(input_tensor)\n",
    "    image_features = _conv2d_bn_relu(image_features, 256, 1)\n",
    "\n",
    "    # Concatenate all features\n",
    "    concat_features = concatenate([d1, d6, d12, d18, image_features], axis=-1)\n",
    "    aspp = _conv2d_bn_relu(concat_features, 256, 1)\n",
    "    return aspp\n",
    "\n",
    "def _residual_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
    "    shortcut = input_tensor\n",
    "    x = _conv2d_bn_relu(input_tensor, filters, kernel_size, padding='same', dilation_rate=strides[0])\n",
    "    x = _conv2d_bn_relu(x, filters, kernel_size, padding='same', dilation_rate=strides[0])\n",
    "    shortcut = Conv2D(filters, (1, 1), padding='same', dilation_rate=strides[0])(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "def deeplab_with_attention(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = _conv2d_bn_relu(inputs, 32, 3, strides=(2, 2))\n",
    "    x = _conv2d_bn_relu(x, 64, 3, strides=(1, 1))\n",
    "    x = _residual_block(x, 64, 3)\n",
    "    x = _conv2d_bn_relu(x, 128, 3, strides=(2, 2))\n",
    "\n",
    "    # Middle block\n",
    "    for _ in range(3):\n",
    "        x = _residual_block(x, 128, 3)\n",
    "    \n",
    "    # Atrous Spatial Pyramid Pooling (ASPP)\n",
    "    aspp = _aspp(x)\n",
    "\n",
    "    # Decoder block\n",
    "    x = UpSampling2D(size=(4, 4), interpolation='bilinear')(aspp)\n",
    "    x = concatenate([x, inputs], axis=-1)\n",
    "    x = _conv2d_bn_relu(x, 48, 3, strides=(1, 1))\n",
    "    x = _conv2d_bn_relu(x, 48, 3, strides=(1, 1))\n",
    "    x = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define Dice loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "    dice_loss = 1 - (numerator + 1) / (denominator + 1)\n",
    "    return dice_loss\n",
    "\n",
    "# Define hybrid loss function combining BCE and Dice loss\n",
    "def hybrid_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    hybrid_loss = bce + dice\n",
    "    return hybrid_loss\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "# Create and compile the model\n",
    "model = deeplab_with_attention(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss=hybrid_loss, metrics=[dice_loss, 'accuracy'])\n",
    "\n",
    "# Train your model\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # Calculate IoU, DSC, Precision, and Recall\n",
    "    iou = tf.metrics.MeanIoU(num_classes=num_classes)(test_labels, predictions)\n",
    "    dsc = dice_loss(test_labels, predictions)\n",
    "    precision = tf.keras.metrics.Precision()(test_labels, predictions)\n",
    "    recall = tf.keras.metrics.Recall()(test_labels, predictions)\n",
    "    \n",
    "    print(f\"IoU: {iou}, DSC: {dsc}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "# Evaluate the model using test data and labels\n",
    "evaluate_model(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Multiply\n",
    "\n",
    "# Define FCN architecture with selective attention mechanism\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Multiply\n",
    "\n",
    "def _conv2d_bn_relu(input_tensor, filters, kernel_size, padding='same'):\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def fcn_with_attention(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = _conv2d_bn_relu(inputs, 64, 3)\n",
    "    c1 = _conv2d_bn_relu(c1, 64, 3)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Add more encoder layers...\n",
    "\n",
    "    # Decoder\n",
    "    uN = UpSampling2D((2, 2))(pN)\n",
    "    uN = concatenate([uN, cN], axis=-1)\n",
    "    uN = _conv2d_bn_relu(uN, 128, 3)\n",
    "    uN = _conv2d_bn_relu(uN, 128, 3)\n",
    "\n",
    "    # Selective Attention Mechanism\n",
    "    attention = Multiply()([uN, pN])  # Apply attention to decoder features\n",
    "\n",
    "    # Final convolution layer\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(attention)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define Dice loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1, 2, 3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1, 2, 3))\n",
    "    dice_loss = 1 - (numerator + 1) / (denominator + 1)\n",
    "    return dice_loss\n",
    "\n",
    "# Define hybrid loss function combining BCE and Dice loss\n",
    "def hybrid_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    hybrid_loss = bce + dice\n",
    "    return hybrid_loss\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 1  # Binary segmentation\n",
    "\n",
    "# Create and compile the model\n",
    "model = fcn_with_attention(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss=hybrid_loss, metrics=[dice_loss, 'accuracy'])\n",
    "\n",
    "# Train your model\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # Calculate IoU, DSC, Precision, and Recall\n",
    "    iou = tf.metrics.MeanIoU(num_classes=num_classes)(test_labels, predictions)\n",
    "    dsc = dice_loss(test_labels, predictions)\n",
    "    precision = tf.keras.metrics.Precision()(test_labels, predictions)\n",
    "    recall = tf.keras.metrics.Recall()(test_labels, predictions)\n",
    "    \n",
    "    print(f\"IoU: {iou}, DSC: {dsc}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "# Evaluate the model using test data and labels\n",
    "evaluate_model(model, test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28303cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
